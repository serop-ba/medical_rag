{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 225 chunks\n"
     ]
    }
   ],
   "source": [
    "# Load web page\n",
    "import argparse\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embed and store\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import GPT4AllEmbeddings, OpenAIEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loader = PyPDFLoader('../..//data/raw/motor_neuron_disease.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "# Split into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "print(f\"Split into {len(all_splits)} chunks\")\n",
    "# vectorstore = Chroma.from_documents(documents=all_splits[:5], embedding=OllamaEmbeddings(model='phi3'))\n",
    "\n",
    "# qdrant = QdrantVectorStore.from_documents(\n",
    "#     all_splits[:5],\n",
    "#     OllamaEmbeddings(model='phi3'),\n",
    "#     path=\"local_qdrant\",\n",
    "#     collection_name=\"my_documents\",\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OllamaEndpointNotFoundError",
     "evalue": "Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull llama2`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOllamaEndpointNotFoundError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm\u001b[39m.\u001b[39;49minvoke(\u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/llms.py:346\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    337\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    338\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    343\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    344\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 346\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    347\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    348\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    349\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    350\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    351\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    352\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    353\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    354\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    357\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    358\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/llms.py:703\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    697\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    701\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    702\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 703\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/llms.py:882\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    868\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    869\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    870\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    880\u001b[0m         )\n\u001b[1;32m    881\u001b[0m     ]\n\u001b[0;32m--> 882\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    883\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    884\u001b[0m     )\n\u001b[1;32m    885\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/llms.py:740\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    739\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 740\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    741\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    742\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/llms.py:727\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    718\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    719\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    724\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    725\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 727\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    728\u001b[0m                 prompts,\n\u001b[1;32m    729\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    730\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    731\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    732\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    733\u001b[0m             )\n\u001b[1;32m    734\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    735\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    736\u001b[0m         )\n\u001b[1;32m    737\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    738\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_community/llms/ollama.py:413\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m generations \u001b[39m=\u001b[39m []\n\u001b[1;32m    412\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m--> 413\u001b[0m     final_chunk \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_stream_with_aggregation(\n\u001b[1;32m    414\u001b[0m         prompt,\n\u001b[1;32m    415\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    416\u001b[0m         images\u001b[39m=\u001b[39;49mimages,\n\u001b[1;32m    417\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    418\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    419\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m     generations\u001b[39m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_community/llms/ollama.py:329\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    322\u001b[0m     prompt: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GenerationChunk:\n\u001b[1;32m    328\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mfor\u001b[39;49;00m stream_resp \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_generate_stream(prompt, stop, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs):\n\u001b[1;32m    330\u001b[0m         \u001b[39mif\u001b[39;49;00m stream_resp:\n\u001b[1;32m    331\u001b[0m             chunk \u001b[39m=\u001b[39;49m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_community/llms/ollama.py:176\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_generate_stream\u001b[39m(\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    170\u001b[0m     prompt: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    174\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m    175\u001b[0m     payload \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt, \u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m: images}\n\u001b[0;32m--> 176\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_stream(\n\u001b[1;32m    177\u001b[0m         payload\u001b[39m=\u001b[39;49mpayload,\n\u001b[1;32m    178\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    179\u001b[0m         api_url\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_url\u001b[39m}\u001b[39;49;00m\u001b[39m/api/generate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    180\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    181\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_community/llms/ollama.py:247\u001b[0m, in \u001b[0;36m_OllamaCommon._create_stream\u001b[0;34m(self, api_url, payload, stop, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[0;32m--> 247\u001b[0m         \u001b[39mraise\u001b[39;00m OllamaEndpointNotFoundError(\n\u001b[1;32m    248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mOllama call failed with status code 404. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMaybe your model is not found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand you should pull the model with `ollama pull \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m         )\n\u001b[1;32m    252\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m         optional_detail \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n",
      "\u001b[0;31mOllamaEndpointNotFoundError\u001b[0m: Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull llama2`."
     ]
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=OllamaEmbeddings(model='phi3'),\n",
    "    collection_name=\"my_documents\",\n",
    "    path='local_qdrant'\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = qdrant.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"phi3\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# llm = ChatOllama(base_url= 'http://localhost:11434', model=\"phi3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The name of the book is \"Motor neurone disease: the use of non-invasive ventilation in the management of motor neurone disease - NICE clinical guideline CG105.\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is the name of the book?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 34 chunks\n"
     ]
    }
   ],
   "source": [
    "# Load web page\n",
    "import argparse\n",
    "\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embed and store\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import GPT4AllEmbeddings, OpenAIEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loader = Docx2txtLoader('../..//data/raw/podcast_transcript.docx')\n",
    "data = loader.load()\n",
    "\n",
    "# Split into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=500)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "print(f\"Split into {len(all_splits)} chunks\")\n",
    "# vectorstore = Chroma.from_documents(documents=all_splits[:5], embedding=OllamaEmbeddings(model='phi3'))\n",
    "\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    all_splits,\n",
    "    OllamaEmbeddings(model='llama3'),\n",
    "    path=\"local_qdrant_podcast\",\n",
    "    collection_name=\"podcast2\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "qdrant = QdrantVectorStore.from_existing_collection(collection_name=\"podcast2\", embedding=OllamaEmbeddings( model='llama3'), path=\"local_qdrant_podcast\" )\n",
    "retriever = qdrant.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", response_metadata={'model': 'llama3', 'created_at': '2024-07-28T19:46:41.66811425Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6722614127, 'load_duration': 43087583, 'prompt_eval_count': 11, 'prompt_eval_duration': 2849224000, 'eval_count': 26, 'eval_duration': 3827461000}, id='run-b7920a1f-6d74-4d37-8d34-4271bead54de-0', usage_metadata={'input_tokens': 11, 'output_tokens': 26, 'total_tokens': 37})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever = qdrant.as_retriever()\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0,\n",
    "    \n",
    "    # other params...\n",
    ")\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "llm.invoke(\"hello\")\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"Give me a title for the podcast episode you just received?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the retrieved context, it seems that the conversation is about data governance, quality, and analysis. Here are some key points:\\n\\n* Data stewards are responsible for ensuring data quality and improving it.\\n* The value derived from data is important to consider.\\n* SQL is necessary for data analysis, but not everyone needs to be an expert in it.\\n* The team has a standardized set of analyses that they run for all countries using Python scripts.\\n\\nSome potential questions that could be answered based on this context include:\\n\\n* What are the responsibilities of a data steward?\\n* How can data quality be improved?\\n* What is the value of data analysis in a business or organization?\\n\\nPlease let me know if you have any specific question you would like me to answer!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"from the podcast, create five key takeaway that i can add to a linkeedIn podcast.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I want to know the title \n",
    "I want to have a linkedin post \n",
    "i want to have a key takeaway for people who don't have time to watch the episode \n",
    "I want to summarize chapters based on time\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredFileIOLoader\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "failed to find libmagic.  Check your installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m loader \u001b[39m=\u001b[39m UnstructuredFileIOLoader(io\u001b[39m.\u001b[39mBytesIO(file_content))\n\u001b[1;32m      4\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mlazy_load()\n\u001b[0;32m----> 5\u001b[0m doc \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(docs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:89\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_load\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Document]:\n\u001b[1;32m     88\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_elements()\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_elements(elements)\n\u001b[1;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39melements\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:327\u001b[0m, in \u001b[0;36mUnstructuredFileIOLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_elements\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[1;32m    325\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39munstructured\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpartition\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m partition\n\u001b[0;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m partition(file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munstructured_kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/unstructured/partition/auto.py:288\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, content_type, file, file_filename, url, include_page_breaks, strategy, encoding, paragraph_grouper, headers, skip_infer_table_types, ssl_verify, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, xml_keep_tags, data_source_metadata, metadata_filename, request_timeout, hi_res_model_name, model_name, date_from_file_object, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mif\u001b[39;00m headers \u001b[39m!=\u001b[39m {}:\n\u001b[1;32m    284\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    285\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe headers kwarg is set but the url kwarg is not. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe headers kwarg will be ignored.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    287\u001b[0m         )\n\u001b[0;32m--> 288\u001b[0m     filetype \u001b[39m=\u001b[39m detect_filetype(\n\u001b[1;32m    289\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m    290\u001b[0m         file\u001b[39m=\u001b[39;49mfile,\n\u001b[1;32m    291\u001b[0m         file_filename\u001b[39m=\u001b[39;49mmetadata_filename,\n\u001b[1;32m    292\u001b[0m         content_type\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m    293\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     file\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/unstructured/file_utils/filetype.py:77\u001b[0m, in \u001b[0;36mdetect_filetype\u001b[0;34m(filename, content_type, file, file_filename, encoding)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m# NOTE(robinson) - the python-magic docs recommend reading at least the first 2048 bytes\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m# Increased to 4096 because otherwise .xlsx files get detected as a zip file\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m# ref: https://github.com/ahupp/python-magic#usage\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m LIBMAGIC_AVAILABLE:\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmagic\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     mime_type \u001b[39m=\u001b[39m magic\u001b[39m.\u001b[39mfrom_buffer(file\u001b[39m.\u001b[39mread(\u001b[39m4096\u001b[39m), mime\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/magic/__init__.py:209\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mreturn\u001b[39;00m m\u001b[39m.\u001b[39mfrom_descriptor(fd)\n\u001b[1;32m    208\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m loader\n\u001b[0;32m--> 209\u001b[0m libmagic \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mload_lib()\n\u001b[1;32m    211\u001b[0m magic_t \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_void_p\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorcheck_null\u001b[39m(result, func, args):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/magic/loader.py:49\u001b[0m, in \u001b[0;36mload_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m   \u001b[39m# It is better to raise an ImportError since we are importing magic module\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mfailed to find libmagic.  Check your installation\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: failed to find libmagic.  Check your installation"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/raw/podcast_transcript.docx\", \"rb\") as file:\n",
    "    file_content = file.read()\n",
    "    loader = UnstructuredFileIOLoader(io.BytesIO(file_content))\n",
    "    docs = loader.lazy_load()\n",
    "    doc = next(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object UnstructuredBaseLoader.lazy_load at 0x31ad9d6d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying brute force chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert at identifying important keynotes in a podcast conversation. \"\n",
    "            \"Only extract important and relevant keypoints that might be interesting for business people and aspiring data scientists. Extract nothing if no important information can be found in the text.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Keynotes(BaseModel):\n",
    "    \"\"\"Information about a the important keynotes from the podcast\"\"\"\n",
    "\n",
    "    description: str = Field(\n",
    "        ..., description=\"what is the important takeaway ?\"\n",
    "    )\n",
    "    evidence: str = Field(\n",
    "        ...,\n",
    "        description=\"Repeat in verbatim the sentence(s) from which the time of the conversation and actual text was taken\",\n",
    "    )\n",
    "\n",
    "class ExtractionData(BaseModel):\n",
    "    \"\"\"Extracted information about key notes from the podcast.\"\"\"\n",
    "\n",
    "    key_developments: List[Keynotes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model='llama3'\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "extractor = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 1 chunks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = Docx2txtLoader('../..//data/raw/podcast_transcript.docx')\n",
    "data = loader.load()\n",
    "\n",
    "# Split into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "print(f\"Split into {len(all_splits)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../..//data/raw/podcast_transcript.docx'}, page_content=\"🎧 Data Tales Recording Session 🎙️-20240617_154331-Meeting Recording\\n\\nJune 17, 2024, 1:43PM\\n\\n1h 9m 41s\\n\\n\\nBaghdadlian, Serop started transcription\\n\\n\\nBaghdadlian, Serop   0:03\\nAlright, so I will just start recording.\\n\\n\\nIllig, Selma   0:03\\nIt's gonna be.\\n\\n\\nBaghdadlian, Serop   0:06\\nBy the way, and at some point we would just start, so don't worry, it doesn't start immediately.\\nSo from my experience, I know I sent you a structure where we say like introduction in the beginning.\\n\\n\\nIllig, Selma   0:12\\nOK.\\n\\n\\nBaghdadlian, Serop   0:19\\nOh, I lost you again.\\nWait, wait.\\n\\n\\nIllig, Selma   0:21\\nNo.\\n\\n\\nBaghdadlian, Serop   0:22\\nNo, you're here.\\nPerfect.\\n\\n\\nIllig, Selma   0:23\\nOK, I'm here.\\n\\n\\nBaghdadlian, Serop   0:23\\nUh, how is?\\nHow is the background?\\nBy the way, how's your background?\\n\\n\\nIllig, Selma   0:27\\nI mean, it's just a should I unblurred I can do it?\\n\\n\\nBaghdadlian, Serop   0:29\\nWould you like to remove the blurry?\\nI don't know.\\nJust maybe if you have like a nice background is also not bad, you can do you have a Mac by the way.\\n\\n\\nIllig, Selma   0:40\\nYeah.\\n\\n\\nBaghdadlian, Serop   0:42\\nSo there's like with the Mac, there's also like some slight blurring or like the studio.\\nI mean, if I do this, then it's a portrait, but there's a studio light.\\nIt makes it looks really nice.\\nDo you know what I'm talking about?\\n\\n\\nIllig, Selma   0:56\\nI'm I mean, I know the background.\\n\\n\\nBaghdadlian, Serop   1:00\\nYeah.\\nOK, I cannot see you now, by the way.\\n\\n\\nIllig, Selma   1:02\\nA it.\\nSorry, what is the background?\\n\\n\\nBaghdadlian, Serop   1:05\\nNo.\\nYeah, that's looks very nice.\\nYeah, you can keep that.\\n\\n\\nIllig, Selma   1:09\\nWhat do you mean the the the artificial one, the?\\n\\n\\nBaghdadlian, Serop   1:11\\nSo this so this looks nice.\\nIf you look top, there's like a green camera button.\\n\\n\\nIllig, Selma   1:17\\nYeah.\\n\\n\\nBaghdadlian, Serop   1:17\\nIf you look at the top bar, if you click on it you see like different options and one of them is a studio light.\\nDo you see that in the HD, camera, FaceTime or whatever?\\nYou have the same mic as me.\\n\\n\\nIllig, Selma   1:30\\nI don't know.\\nI can't click on anything.\\n\\n\\nBaghdadlian, Serop   1:32\\nOK.\\nAlright, then maybe you don't have it.\\nIt's like a nice feature.\\nIt makes the lighting looks so I don't know.\\n\\n\\nIllig, Selma   1:39\\nUmm.\\n\\n\\nBaghdadlian, Serop   1:40\\nDo you see now the difference?\\n\\n\\nIllig, Selma   1:43\\nYeah. Wow.\\n\\n\\nBaghdadlian, Serop   1:44\\nYeah.\\nSo it adds, it adds a little bit of like studio light.\\n\\n\\nIllig, Selma   1:48\\nHmm. Handy.\\n\\n\\nBaghdadlian, Serop   1:49\\nBut I thought it's like with all Max.\\nI'm not sure.\\nYeah.\\nSo how's it going?\\nHow's it going with you?\\n\\n\\nIllig, Selma   2:01\\nPut a you know we have lots of activities and students and our team right now.\\nAnd so that's what what keeps me occupied is teaching sequel to people that don't know sequel and.\\n\\n\\nBaghdadlian, Serop   2:08\\nOhh sounds fun.\\nOhh OK.\\nDo you like it?\\n\\n\\nIllig, Selma   2:15\\nAnd so I it's good.\\n\\n\\nBaghdadlian, Serop   2:16\\nHow do you find it?\\n\\n\\nIllig, Selma   2:18\\nI have to go back to the basics of your life.\\nYou know there is something to take for granted and then you try to explain it to someone you're like, I have no idea how to explain that.\\nYou know, it just works.\\n\\n\\nBaghdadlian, Serop   2:29\\nFunny enough, he's yeah, funny enough.\\nHe said this.\\nWe also added like an intern.\\n\\n\\nIllig, Selma   2:33\\nYeah.\\n\\n\\nBaghdadlian, Serop   2:34\\nNow that I'm also mentoring and he wanted to learn SQL, so also one of the first tasks that we gave him was to learn the basics of SQL and come up with a fake database and do that and do this, it makes you think like Oh my God, like it's very interesting to go back to the basics.\\n\\n\\nIllig, Selma   2:37\\nNow.\\n\\n\\nBaghdadlian, Serop   2:53\\nBut then there's like a lot of resources online, but then there's not a lot of like structured way like you need to still like gather the bits and pieces from all these tutorials to make like something.\\n\\n\\nIllig, Selma   2:53\\nYeah.\\nYeah.\\nYeah.\\nYeah.\\nYeah, like he did a very long and very extensive cycle course, but then we realized, you know, there's a big difference between doing an online course where you have all of these lectures and denoiser and this one, we do a left join and then the next one we learn about window functions and whatever.\\nAnd then you get your first task and it's like tell me which store was profitable last year and then out of a sudden we have to like you know, put all of these pieces together.\\n\\n\\nBaghdadlian, Serop   3:21\\nMm-hmm.\\nYeah.\\nHmm yeah.\\n\\n\\nIllig, Selma   3:35\\nAnd yeah, that's the really tough stuff.\\n\\n\\nBaghdadlian, Serop   3:35\\nIs it very interesting skill?\\nYeah.\\nYeah, that's that's true.\\nThat's true.\\nDepends what they wanna do.\\nI mean the Internet right now, that's still don't know the direction where the data science or data analyst or whatever.\\nSo it's also hard to come up with tasks for them, but it's it's a super interesting like to mentor someone else and design a personal development plan and all this kind of stuff.\\n\\n\\nIllig, Selma   3:53\\nYeah.\\n\\n\\nBaghdadlian, Serop   3:58\\nSo this kind of kind of cool, you know what else you been?\\n\\n\\nIllig, Selma   4:01\\nAnd I mean SQL, they need all of them.\\nNeed to know you're you can't get around it.\\n\\n\\nBaghdadlian, Serop   4:05\\nThat's true.\\nThat's true, but to be honest, like for me like as a data scientist or what I need from sequel is like select star and I let you guys do the hard work, do the data engineering.\\nUmm yeah.\\nBut other than that, what else you've been up to?\\n\\n\\nIllig, Selma   4:23\\nUmm well, it's just this one come into.\\nThat's really funny that you say that because our team it's the exact opposite cause.\\nFelix does this really complex long term analysis.\\nWe're, you know, he generates data for the past two years and then he analyzes the behavior of churners and everything like, wow.\\nLike you know SQL so well, so please teach me.\\nAnd I'm just like, do you know we copy some data from the star schema and just apply some filters somewhere and we're done?\\n\\n\\nBaghdadlian, Serop   4:52\\nMm-hmm.\\n\\n\\nIllig, Selma   4:53\\nAnd like way less complex than what Felix analyzes sometimes.\\nYeah, it's really interesting.\\n\\n\\nBaghdadlian, Serop   4:57\\nUmm, just just for context.\\nBy the way, Felix is a the data scientist, right?\\n\\n\\nIllig, Selma   5:01\\nYeah.\\n\\n\\nBaghdadlian, Serop   5:01\\nJust for that context.\\n\\n\\nIllig, Selma   5:02\\nYeah, exactly, exactly.\\n\\n\\nBaghdadlian, Serop   5:02\\nOK, she just wants if somebody doesn't know it's really exists, let's also add the the the job titles and I know, but does he does he do it with SQL like the whole analysis or usually like what I do like I query it and then I put some pandas or do something in Python.\\n\\n\\nIllig, Selma   5:07\\nYeah.\\nThat's good.\\nYou know.\\n\\n\\nBaghdadlian, Serop   5:19\\nThat's like kind of my tech stack. Umm.\\n\\n\\nIllig, Selma   5:22\\nYeah.\\nYeah, so similar.\\nLike usually we also, you know, load it into into, put a notebook and then yeah, exactly use pandas and then visualization libraries and everything.\\nBut then for the churn project, we also have kind of a standardized set of analysis that we run for all countries and that you know we put into a Python script and then also automated.\\n\\n\\nBaghdadlian, Serop   5:41\\nMm-hmm.\\n\\n\\nIllig, Selma   5:44\\nSo we can do that now in an automated way and don't have to run to put a notebooks. Yeah.\\n\\n\\nBaghdadlian, Serop   5:49\\nNice.\\nYeah, yeah.\\nYeah.\\nWhy you have you have you have a problem with the Jupyter notebooks.\\n\\n\\nIllig, Selma   5:52\\nSo that's pretty cool.\\nI think if you come from a software engineering background to put a notebooks tend to be very, you know, long and complex and confusing and you mix your infrastructure with your code logic with your images and visualizations.\\n\\n\\nBaghdadlian, Serop   6:01\\nAlright.\\n\\n\\nIllig, Selma   6:14\\nAnd then I remember when we discussed about switching to Vertex AI and using Vertex Pipelines, another data scientist showed up with their did and they were scrolling for like 10 minutes in their little notebook trying to find the pipelines.\\n\\n\\nBaghdadlian, Serop   6:14\\nMm-hmm.\\n\\n\\nIllig, Selma   6:30\\nAnd you know, me and my colleague who's also bore software engineer than a data engineer.\\nWe looked at this.\\nWe were like, no.\\n\\n\\nBaghdadlian, Serop   6:37\\nNo, this is not working.\\n\\n\\nIllig, Selma   6:37\\nNo, let's not do that then.\\nThis looks like this looks really good.\\n\\n\\nBaghdadlian, Serop   6:39\\nUh, I hope this data, this other data side.\\nThis is not me, by the way.\\nI don't know.\\n\\n\\nIllig, Selma   6:45\\nBut it wasn't I I think you know if if a data scientist has to do a lot of data pipelines and you know heavy data workflows, it's it's very useful because you know you stay in one tool, you don't have to learn additional things.\\n\\n\\nBaghdadlian, Serop   6:45\\nSounds like something I would do.\\nI don't know.\\n\\n\\nIllig, Selma   7:00\\nBut you know us having more engineering resources we you know, can do other things.\\nWe're intending rentons and and debugging reviews and a little bit easier than scrolling through a notebook.\\n\\n\\nBaghdadlian, Serop   7:05\\nUmm.\\nI can.\\nI can imagine.\\nI can imagine it's actually now like I can see it also becoming a requirement right?\\nLike to move away from notebooks and try to do something that's more version controlled and I don't know using pipelines and YAML files and at least is how we started doing it, but it is a mindset shift, so you need also to educate the data scientists like, hey, OK or I don't know, maybe outsource it to somebody else.\\nNo.\\nHow is it in your experience like?\\nHave you seen a transition from like notebook to like production code?\\nIs it an easy transition?\\nDo you usually like pick up a random notebook from a data scientist and then try to make it production ready?\\nOr do you expect now the data scientists to know all these software engineering but simples?\\n\\n\\nIllig, Selma   8:02\\nYeah, it's my little guilty pleasure that I love taking Jupiter notebooks and making it production ready.\\nIt's what I started to do at university, which is one of my one of the projects I worked on was, you know, how do we integrate better software engineering principles into data science.\\n\\n\\nBaghdadlian, Serop   8:20\\nOK. Mm-hmm.\\n\\n\\nIllig, Selma   8:21\\nAnd I love it.\\nI think it's really fun too, then actually.\\nSee, you know what kind of reproducible steps where we, you know, can we pull out functions?\\nWhere do we have helper functions that we know move out completely?\\nWhere do we separate infrastructure from?\\nBusiness logic.\\n\\n\\nBaghdadlian, Serop   8:36\\nUmm.\\n\\n\\nIllig, Selma   8:36\\nHow do we test?\\nYou know, how do you test machine learning?\\nIt's it's super difficult.\\nIt's what I really like and I think what you can see there also is, you know how the field develops.\\nThe you know, is this quote about you know, how data science, the hottest chop out there, but then it changed so much, you know, it's not just being a data scientist anymore.\\nThere are so much domain knowledge now to it and things that get added to it that you expect from your people.\\nThat one single person can't learn anymore.\\nSo I don't wanna say you need to specialize for.\\n\\n\\nBaghdadlian, Serop   9:08\\nUmm.\\n\\n\\nIllig, Selma   9:10\\nThere's only so much a person can know and can be proficient in it, and so, you know, we have all of these new little titles that now pop up everywhere from, you know, analytics engineer to data steward to we have data product managers now, you know, and each of them have their own little set of skills.\\nAnd so just adding up skills to data scientists won't work.\\n\\n\\nBaghdadlian, Serop   9:26\\nInteresting.\\n\\n\\nIllig, Selma   9:31\\nI think you you make it even harder for people to move into data science if you'd be like ohh, but you actually also have to be a software engineer like nice that you know all of this advanced you know, statistics, machine learning and these kind of things.\\n\\n\\nBaghdadlian, Serop   9:44\\nUmm.\\n\\n\\nIllig, Selma   9:45\\nBut then we also expect you to be a software engineer that just won't work and so.\\n\\n\\nBaghdadlian, Serop   9:51\\nOhk.\\nOK.\\n\\n\\nIllig, Selma   9:51\\nUh.\\n\\n\\nBaghdadlian, Serop   9:52\\nSo what's so if if a data scientist now wants to go into the market and seems like everywhere in like I see snow already?\\nLike if you look for like job, what's the word like job applications like they now expect you to like ohh.\\nLike, be proficient into deploying these model, so it's not only just training and working in a notebook and then expecting software developers to deploy it, but it's also the expectation.\\nLike OK, you need to do the whole shebang from A-Z and it's kinda like intimidating, especially for someone who hasn't.\\nEven maybe they not even used to get or something.\\nI mean, I assume now this is like common knowledge I feel because it's been pushed by accompanies and best practices.\\nBut yeah, it's still surprised you.\\nIt's like company dependent.\\nI work with data scientists that were purely just notebook and like are or like some statistics and they were like very highly educated in this stuff.\\nBut then, like like the basic software development, and then if the company maybe is a startup and they don't have the funding to add engineers, then yeah, you have to do the work yourself, buddy.\\nAnd good luck.\\nLike it's gonna.\\nIt's gonna be tough.\\nUmm, but yeah, what was your what do you think about this?\\n\\n\\nIllig, Selma   11:02\\nYeah.\\n\\n\\nBaghdadlian, Serop   11:05\\nHow do people upskill like if they not need A or B?\\nHow would they go with this?\\n\\n\\nIllig, Selma   11:11\\nNo, I think this really shows, you know which companies are really good companies when it comes to data science and which are just ones were like ohh.\\nLike we kind of missed this development.\\nNow we need to add data people to our team and I think that you can really see, you know, what are the ones that have also good leadership when it comes to data.\\n\\n\\nBaghdadlian, Serop   11:24\\nUmm.\\nMm-hmm.\\n\\n\\nIllig, Selma   11:33\\nIn the end, everything can be learned.\\nYou know, like very and it's also very dependent on the text at the company is using.\\nSo they're probably will never be a perfect match, and I think also you're you're yourself need to figure out, do you want to apply now for a job where you will stretch where you will have to learn a lot of new things and you know, it really get all of your comfort zone.\\nOr do you look like something similar?\\nWhat you have been doing before, or just maybe you'd wanted to move into a different industry and maybe learn something new there.\\nAnd then, you know, I think there are, like, there's so many data drops out there right now.\\nI think you will find something if you be a little bit strategic about it.\\nYou know, I think it totally makes sense to have these development plans and figure out where you want to move into, but yeah, then it depends again, so much in which team you will go, which company, what text like they're using and you will never fulfill all criterias.\\n\\n\\nBaghdadlian, Serop   12:27\\nUmm.\\nCode.\\n\\n\\nIllig, Selma   12:35\\nI don't think it's possible.\\nThere's so much out there.\\n\\n\\nBaghdadlian, Serop   12:38\\nUmm, you mentioned like there's so many different data titles.\\nWhat?\\nWhat is the data steward?\\nI've never heard of this.\\nWhat does that person do?\\n\\n\\nIllig, Selma   12:45\\nYeah, you know that that is this new development now where we realized ohh wait data governance is actually important like we can't just ingest data into a data lake and be like you know like the data is there do something about it like we have so much time to go analyze it.\\n\\n\\nBaghdadlian, Serop   12:53\\nYeah.\\nThe data is there, yeah, yeah.\\n\\n\\nIllig, Selma   13:03\\nUmm.\\n\\n\\nBaghdadlian, Serop   13:03\\nUmm.\\n\\n\\nIllig, Selma   13:04\\nAnd then you know, data stewards are kind of responsible for that.\\nIt's like, you know, being the owners may be the wrong word, but kind of, you know, looking at it being like, OK, what do we ingest?\\nWhat's the quality here?\\nWho needs to improve the data quality?\\nWhat does this data used for?\\nYou know where the dependencies and there's good software.\\nI guess you can buy in that also shows you all of these things, but then you need to have one person who actually looks at it and whose goal it also is to improve.\\n\\n\\nBaghdadlian, Serop   13:27\\nUmm.\\n\\n\\nIllig, Selma   13:31\\nUh yeah, data governance?\\nData quality.\\n\\n\\nBaghdadlian, Serop   13:34\\nHmm.\\n\\n\\nIllig, Selma   13:34\\nThe value that is derived from data.\\n\\n\\nBaghdadlian, Serop   13:37\\nYou know, it seems to be also like one of. Uh-huh.\\n\\n\\nIllig, Selma   13:37\\nYeah.\\nAnd there are different names for it.\\n\\n\\nBaghdadlian, Serop   13:41\\nSo, like OK, at least like for us it's just to be one of the most crucial elements.\\n\\n\\nIllig, Selma   13:43\\nNo.\\n\\n\\nBaghdadlian, Serop   13:46\\nIt's like the missing piece.\\nIt's like everybody want a data product and then you go back into the data and you realize like the beginning was done wrong.\\nAnd then it kind of like ruins your whole pipeline towards the end.\\nUh, it's just good that now companies are getting more, becoming more conscious into like what is needed and somebody like that is like for us it's it would be so good, especially when you get like tables with people get so creative with naming like different columns and then not even telling you what it is or having stuff like customer ID but the same customer ID has been renamed like 10 times as like customer key customer and then you don't even know if the same things map to the same things or especially if people also use the.\\nSame IDs for something else and yeah, I know, like in academia they tell you about data quality and then it's like ohh.\\nLike, it's really scary thing, but then you don't know what you're up against at till you go to industry and realize what kind of stuff that might happen.\\nAnd especially some stuff you think like so common sense and still they happen like giving IDs to different people, which is like probably a business need like it's not like people are just love to play around with these kind of stuff.\\nBut it's it's so tough.\\nWhat kind of like nice data quality example I know, like you were the 1 to go to when when it comes to data quality.\\nSo like what have you seen that maybe make you laugh where like it was a surprising example that you encountered in industry?\\n\\n\\nIllig, Selma   15:17\\nYeah, I I think the favorite one from Metro is, you know, they've started investing now into the data catalog and trying to, you know, make data more available than discoverable and everything which is the perfect way to go.\\n\\n\\nBaghdadlian, Serop   15:28\\nUmm.\\n\\n\\nIllig, Selma   15:32\\nThis is definitely what we need to do, but then you know you search for customer and you get 300 tables all slightly different and you never know.\\n\\n\\nBaghdadlian, Serop   15:34\\nMm-hmm.\\nOK.\\nYeah, yeah.\\n\\n\\nIllig, Selma   15:42\\nYou know what?\\nWhat is the right table?\\nNow you know what can we use?\\nWho is the contact person?\\nWho can answer these things?\\nAnd then, you know usually with these kind of more established companies, you have these people that have been around forever that have seen everything and these are the ones you go to and ask, you know, whenever they leave the company, like you're really in trouble.\\n\\n\\nBaghdadlian, Serop   15:49\\nMm-hmm.\\nYeah, yeah.\\nOhh it's yeah umm no.\\n\\n\\nIllig, Selma   16:06\\nNow the ones who can explain you know how to stitch data and how how these customer ideas work.\\nLike, who knows their 20 and they all used in different contexts.\\n\\n\\nBaghdadlian, Serop   16:11\\nMm-hmm.\\nUmm.\\n\\n\\nIllig, Selma   16:16\\nThey're probably all very reasonable, like like some smart person has thought about it.\\nUmm, but then you never know the history and I think this is also the big difference between data drops and startups and data drops in these like you know more established companies is with startups you have to you know it's ground up everything you have very little resources, lots of requests you need to perform and then you use a lot of you know off the shelf software that's also usually very good because you know it's companies behind it selling it being dependent on their software quality and then you have these more traditional or more established company.\\n\\n\\nBaghdadlian, Serop   16:24\\nYeah.\\nUmm.\\n\\n\\nIllig, Selma   16:53\\nWho are also interviewed for my bachelor thesis, where you see technically they are all quite far already.\\nYou know they are in the cloud.\\nThey're using all of these, like really advanced technologies, but then the organization is not there yet and you see no they data quality problems.\\nThey have this problem of everyone's asking for a single source of truth.\\nYou know, like, what is the right one?\\n\\n\\nBaghdadlian, Serop   17:16\\nUmm.\\n\\n\\nIllig, Selma   17:17\\nWhat should we use?\\nAnd then there is no answer to it, cause nobody knows.\\nNobody wants to make a decision in the end because they only they know they're little domain.\\nUmm.\\nAnd that's what makes it so different.\\nAnd that's where I think also switching industries.\\nThere is actually quite difficult because startups operate totally different than us, for example.\\n\\n\\nBaghdadlian, Serop   17:38\\nNo.\\nUmm, you mentioned something about your bachelor thesis, so it was.\\n\\n\\nIllig, Selma   17:41\\nYeah.\\n\\n\\nBaghdadlian, Serop   17:44\\nCan you tell us what you've done there?\\n\\n\\nIllig, Selma   17:47\\nYeah.\\nSo that was my.\\nSo to graduate from university attitude, a final project which I did with Metro it during my internship.\\n\\n\\nBaghdadlian, Serop   17:54\\nUmm.\\n\\n\\nIllig, Selma   17:57\\nBut then we also had to write a thesis.\\n\\n\\nBaghdadlian, Serop   17:57\\nOK.\\n\\n\\nIllig, Selma   17:59\\nAnd we're also interesting.\\nI come from a university where working in a startup is highly desirable and everybody wanted to go to startups.\\nWe're like, Oh my God, this is the best way of working, especially also as a software engineer.\\n\\n\\nBaghdadlian, Serop   18:08\\nUmm.\\n\\n\\nIllig, Selma   18:12\\nYou work with like these.\\n\\n\\nBaghdadlian, Serop   18:12\\nYeah.\\n\\n\\nIllig, Selma   18:13\\nSuper cool new technologies.\\nAnd then I did my internship that's made when I was like wait.\\nBut actually, you know, we also work with Super new technology.\\nSo why is it so different?\\nAnd then I wrote my fears about basically best practices for data science teams.\\n\\n\\nBaghdadlian, Serop   18:23\\nUmm.\\n\\n\\nIllig, Selma   18:29\\nIn these like bigger, more established companies who, you know were already successful before you, this data transformation, umm and yeah I interviewed 5 kind of business leader data experts from 5 different companies and asked them what their yeah best practices but their challenges are.\\nAnd it was very eye opening for me in a way that, you know, technically there aren't so many problems.\\nYou know that data science is advancing and they're the new technologies and new use cases that you could use if this generative AI hype now.\\nBut the big problem often lie on an organizational side, or the way they're data is set up.\\nThe way that teams are structured, the teams are working and that they need to improve their way more and they will probably be like create more valuable work if they would invest into their teams and into their structure then investing into technology because they are already quite advanced.\\n\\n\\nBaghdadlian, Serop   19:16\\nUmm.\\nHmm.\\nOK.\\nYou mentioned very good points.\\nLet's let's digest some like 1 dimension at a time.\\nThe first thing like Team structure you said, So what?\\nWhat kind of stuff have you seen in data science versus like what is maybe the optimal?\\nLike, what's the team structure that you believe is it makes sense to to adopt?\\n\\n\\nIllig, Selma   19:51\\nYeah.\\nAnd So what we can see on two opposite ends, so you can have very centralized data science teams or you can have very decentralized data science teams and there you can also look at software engineering and product teams and see how they structure because it's usually very similar.\\nSo with centralization usually have this group of data, scientists that work together with other stakeholders on a project basis and you know they exchange a lot.\\n\\n\\nBaghdadlian, Serop   20:21\\nHmm.\\n\\n\\nIllig, Selma   20:23\\nThey also rotate depending on, you know who's in need right now.\\nAnd then on the other end, you have this very decentralized approach, which is also what we have as METRO.\\nAs this you have product teams and then you know some product teams are more data science heavy like your my team, maybe there's a lot of data scientists, data engineers and the product manager who's very technical.\\n\\n\\nBaghdadlian, Serop   20:32\\nUmm.\\n\\n\\nIllig, Selma   20:43\\nBut then you also have single data scientists or data analysts in product teams.\\nThey're doing the data work there.\\nAnd what one can observe is that that also changes.\\nSo, umm, usually?\\nUh Data science team.\\nStart with a more centralized approach.\\nUsually start hiring 1, two or three people and then you know things grow.\\nYou add more people, you distribute them, but then these kind of you have this growing pain of you add more people, you don't have enough supportive infrastructure, not enough people that set best practices and guidelines and blueprints and everything.\\n\\n\\nBaghdadlian, Serop   21:17\\nUmm.\\n\\n\\nIllig, Selma   21:25\\nAnd then you start to centralize again.\\nThen there is this.\\nWhat's your favor?\\nAnd data science words, called a center of excellence, just the way it evolves and how companies sometimes.\\nSo there's also names like inside squads or, you know, business Intelligence Center or like there are different names but but usually you have this centralized team then which are setting the standards which are doing the very innovative very difficult topics.\\nBut then you kind of have, like satellites, other data scientists and or data people in general in other teams who then have the domain knowledge because that is what's missing for these centralized teams is they usually don't have the domain knowledge, they have lots of knowledge about data science and how to do data science projects.\\n\\n\\nBaghdadlian, Serop   22:02\\nUmm.\\n\\n\\nIllig, Selma   22:07\\nBut they're completely like separate from business units and don't speak their language in a way which you, you know, then counteract by putting data people actually in there.\\n\\n\\nBaghdadlian, Serop   22:08\\nUmm.\\nUmm.\\nHmm.\\n\\n\\nIllig, Selma   22:18\\nThen they learn the business knowledge, but also the business people can learn from them on a daily basis and you try to bridge that gap.\\n\\n\\nBaghdadlian, Serop   22:22\\nUmm.\\nOK.\\nAnd if we have like data scientists on like one side, let's say we gather, I don't know, we hire ten data scientists to have like a data science task.\\nWhere would the engineers be like?\\nLet's say we need someone to deploy or like data engineers to prepare the data.\\nOr maybe actually we should after this go into?\\nMaybe if somebody doesn't know, just like the difference between the jobs, like what is who is doing what, because I know it's a company dependent definition, but with the engineers be then in the teams.\\nOr would they also be like a separate centralized engineering team?\\nThat's sometimes they called ML platform or something like this and then they would provide services to the data scientists and help them out with the deployment.\\nAnd then yeah, I don't know.\\n\\n\\nIllig, Selma   23:08\\nYep.\\n\\n\\nBaghdadlian, Serop   23:10\\nJust tell me how, how.\\nHow is it?\\n\\n\\nIllig, Selma   23:11\\nYeah, yeah, I think it's the same way.\\n\\n\\nBaghdadlian, Serop   23:11\\nHow is the structure?\\n\\n\\nIllig, Selma   23:13\\nAgain, you can have it very centralized.\\nYou know, having an ML platform that everyone can just use their what one could read up on if they're interested in is this topic of Team topologies, where talks about teams you need to have in a company for building software projects.\\nBut it's very similar for for data projects in a way you have the teams that are actually working on it which have the business knowledge.\\nYou need some supportive teams around it.\\nSo for example, with our very decentralized and approach right now, there is no common way to deploy an ML project.\\nI think every team right now decides on their own what kind of resources they have, how they want to do it.\\n\\n\\nBaghdadlian, Serop   23:50\\nTrue.\\nMm-hmm.\\n\\n\\nIllig, Selma   23:54\\nAnd of course, it's all the cloud based and there's a set of tools I think everybody can kind of agree on, but it's still very different.\\nAnd if you, you know, switch out engineers.\\n\\n\\nBaghdadlian, Serop   24:03\\nHello. The stop.\\nStop for a second.\\n\\n\\nIllig, Selma   24:05\\nUmm. Whoops.\\n\\n\\nBaghdadlian, Serop   24:05\\nYour voice is.\\n\\n\\nIllig, Selma   24:11\\nOK, it's that looks good.\\n\\n\\nBaghdadlian, Serop   24:12\\nAll good.\\nI can hear you now again, but for some reason it disappeared for a second.\\n\\n\\nIllig, Selma   24:17\\nOK.\\n\\n\\nBaghdadlian, Serop   24:19\\nOK.\\nOK.\\nUh, so we were talking about, can you hear me or is it broken down again?\\n\\n\\nIllig, Selma   24:23\\nLet's say.\\nYeah, I can hear you.\\nI was.\\nNo, no, I can hear.\\n\\n\\nBaghdadlian, Serop   24:28\\nOh, OK.\\nYou're gathering your thoughts again.\\n\\n\\nIllig, Selma   24:32\\nYeah, I like went on this big rent.\\n\\n\\nBaghdadlian, Serop   24:33\\nOK, no worries.\\nYeah.\\nNo, all good.\\nSo we were talking about like the METRO structure because it's decentralized.\\nAnd what do you think there was the maybe challenges that we were facing from the decentralized structure?\\n\\n\\nIllig, Selma   24:41\\nYeah.\\nYeah.\\nSo with that decentralized structure you have this problem that every team kind of decides on their own what they want to do, what kind of technology they want to use, what people are part of that you're already hinted at that we need to talk about roles, but this is also very different in the teams.\\nAnd so you know, each and everyone can decide on their own what they want to do.\\nAnd then it's hard to, you know, switch people.\\nYou know, if somebody leaves and you hire a new person, then it's very set on what they need to know in order to, you know, fill that position again, which now if you have a more centralized approach, it's a little bit easier, you know, sharing the tech stack, sharing documentation and knowledge of that is is easier.\\n\\n\\nBaghdadlian, Serop   25:21\\nUmm.\\n\\n\\nIllig, Selma   25:32\\nBut then of course you create bottlenecks.\\nI think this is the big disadvantage of having centralized approach is you have a bottleneck.\\n\\n\\nBaghdadlian, Serop   25:39\\nHmm.\\n\\n\\nIllig, Selma   25:41\\nIf that team doesn't deliver as fast as you wanted, or also for business stakeholders, you know there may be, you know, 5-6 different stakeholders coming at the same time wanting something you know you then power artist and be like, OK, sorry, you 4, but we will work on the other two projects first, then nothing happens.\\nThat is very different when you're decentralized and where resource planning actually happens in the teams.\\n\\n\\nBaghdadlian, Serop   26:06\\nUmm.\\nWell, let's play the blame game.\\nLike if we are doing it centralized approach who are usually which team is usually the bottleneck?\\nIs it the engineers or the data scientists in your experience?\\n\\n\\nIllig, Selma   26:19\\nI actually think it's usually engineering, but because most people underestimate how much work it actually is, you know, they're just think like ohh like just deploy it like ohh wait a minute.\\n\\n\\nBaghdadlian, Serop   26:22\\nUmm.\\nThat's true, yeah.\\n\\n\\nIllig, Selma   26:31\\nLike I can just deploy it, but then we haven't talked about, you know, monitoring and recovery and you know processes that happen in the backseat.\\n\\n\\nBaghdadlian, Serop   26:37\\nInsecurity.\\n\\n\\nIllig, Selma   26:39\\nCurity.\\nYes, another good one.\\n\\n\\nBaghdadlian, Serop   26:40\\nHmm hmm.\\n\\n\\nIllig, Selma   26:41\\nAnd and people tend to underestimate that, whereas in data science, you know in the beginning it's a lot about conceptualizing and you know you go together with your stakeholders and each week, you know, have a little bit of an advancement.\\n\\n\\nBaghdadlian, Serop   26:50\\nUmm.\\n\\n\\nIllig, Selma   26:54\\nAnd you went a little bit further and you explored some of the things you can show it engineering, you know it either works or it doesn't.\\nSo.\\nSo there's very little steps in between where you can actually show progress.\\n\\n\\nBaghdadlian, Serop   27:01\\nUmm.\\nUmm.\\n\\n\\nIllig, Selma   27:05\\nUmm.\\nAnd I mean, let's face it, usually also the engineers are not the best when it comes to soft skills.\\nAnd actually, you know, keeping stakeholders in the loop.\\nGood project management.\\nI think it's something especially junior stuff when you're struggling a lot with and so, uh, yeah, I should hard to observe what they were actually doing.\\n\\n\\nBaghdadlian, Serop   27:21\\nUmm.\\n\\n\\nIllig, Selma   27:27\\nAnd then you think like, oh, that's such a bottleneck, but you don't even see what they're doing.\\n\\n\\nBaghdadlian, Serop   27:32\\nYeah, by the way, all the love to the engineers.\\nI mean, we're both engineers, so we don't want to get any hate from everybody.\\nWe just, we just like laughing around here.\\nBut it's interesting that you mentioned that also in decentralized approach like there could be bottlenecks because at the moment we have a no, no sorry.\\nYou said in the centralized approach we have a bottleneck or in the decentralized so both it doesn't, yeah.\\n\\n\\nIllig, Selma   27:56\\nIn the centralized and I mean it happens in both probably, but in that centralized you have the centralized function of.\\nMaybe you know the platform team or the Group of data scientists were then prioritizing different projects.\\n\\n\\nBaghdadlian, Serop   28:09\\nHmm.\\nOK.\\nBecause it's very interesting because at the moment we do, we have a decentralized, as you mentioned at Metro and the the date, the data scientists and the engineers works together.\\nAnd what we notice is there is usually like in data development and in like if you have a data product then usually as you said like the data scientists would come up with like the concept, the POV POC and then you have a finished product and then you need to deploy it.\\nBut then, technically your job is done as a data scientist, right?\\nAnd if you're bounded to this product, there is no flexibility that you maybe can pick up something else until the engineering catch up because they need to do the best practice, the security layer, the deployment, the scalability.\\nSo what usually happens is is like in that period where you kind of like waiting for the things to be deployed and stuff to be accomplished.\\nThere is maybe not so much to do for data science and then you would think like, OK, maybe if you're working in a centralized way we can pick up another task from, I don't know from another group and you'll be more flexible and that would solve that issue.\\nBut apparently also with the centralized approach, you can also have bottlenecks and then still.\\nI don't know.\\nI don't know what's what's the best way to.\\n\\n\\nIllig, Selma   29:27\\nNo. Yeah.\\n\\n\\nBaghdadlian, Serop   29:31\\nTo solve this issue, it seems to be very difficult.\\n\\n\\nIllig, Selma   29:31\\nYeah, I think they're again, it's two ways.\\nLike, apparently the engineers and your team needs some more structure and some more support so they don't have to come up with everything on their own because it just seems like a very heavy workload that they're facing, which maybe could be, you know, lifted by having another supporting team, you know, that could also be, you know, a data model in other companies where you know, you don't have to do much data engineering because there's actually a central data model that you can work with or deployment and monitoring is easier because there is this no platform that.\\n\\n\\nBaghdadlian, Serop   29:43\\nOK.\\nYeah.\\nMm-hmm.\\n\\n\\nIllig, Selma   30:05\\nYou know, it's just click and your models deployed and in the other way and that's again where I come back to my little spicy opinion from my bachelor thesis is we can learn so much from software engineering or from from classical product development because that is a similar project they were facing where you know the product managers and the designers had nothing to do.\\n\\n\\nBaghdadlian, Serop   30:21\\nUmm.\\n\\n\\nIllig, Selma   30:26\\nThey explored the new and with feature.\\nFor example, they did the little User Research, their tests, and now they handed it over to the engineering.\\nSo now they're waiting for them to finish that feature before they can then pick it up again and improve it.\\nAnd you know, they, for example, came up with this dual discovery process where they say, OK, but we keep discovering it just needs to be very well planned on what we're gonna pick up next.\\n\\n\\nBaghdadlian, Serop   30:40\\nUmm.\\n\\n\\nIllig, Selma   30:49\\nSo you can continue working well.\\nOther people also continue their work.\\n\\n\\nBaghdadlian, Serop   30:55\\nUmm.\\n\\n\\nIllig, Selma   30:55\\nSo it's a, it's a collaboration problem in a way that you need to understand how to improve these handshakes.\\nSo maybe the engineers can start earlier then the data scientists finishing his PUC like maybe there's already some preparation work that can be done.\\nBut then also, what can we continue to discover while maybe the engineers are making the model production ready?\\n\\n\\nBaghdadlian, Serop   31:10\\nMm-hmm.\\nMm-hmm.\\n\\n\\nIllig, Selma   31:20\\nAnd that's I think where you know really good product managers come into play.\\nIt's like this is like this is really shows you where really good product managers are and where like you know they're really skilled on you know, preparing stakeholders and preparing new interesting problems.\\nAnd then making sure that the team can, you know, continue working and then we'll stay in this flow state where where you every day, you know what you're working on and what's next.\\n\\n\\nBaghdadlian, Serop   31:49\\nHmm.\\nYeah.\\nAnd in our experience, also like product managers, they need to be kind of coming from data domain like product management for a data product is a little bit different than for like a software development.\\n\\n\\nIllig, Selma   31:51\\nBut.\\n\\n\\nBaghdadlian, Serop   32:02\\nAnd for lack of resources, usually you get people who are very good at software development, so they are product managers and it was like a basic not a basic, but like a very.\\nWhat's the word?\\nVery traditional software development product where there's like there's a back end or front end or whatever.\\nSo there's like, you know, how things going to work and you have a definite process and then they switch to a data project and then this is where they kind of feel like, OK, things are different here.\\nUmm one thing that for example I heard from product managers is especially in our decentralized project is they expect everybody to pick up any task and this is especially if you have like highly specialized data scientists who maybe have been working with a notebook or whatever.\\nBut they are great at it.\\nAnd then you have a software developer who's working on security.\\nYou obviously cannot expect the data scientists to build a very good, secure application coming from a background of notebooks.\\nAnd then this is where like the flow of thinking starts and then you need to be really good as you said at your work to kind of know where your expertise lie and plan accordingly.\\nLike maybe you need six more engineers.\\nI heard the rule of thumb is like for every data scientist you need two engineers or something like this.\\n\\n\\nIllig, Selma   33:23\\nNo.\\n\\n\\nBaghdadlian, Serop   33:23\\nSo yeah, it's like you need to really know how much time consuming stuff are the capabilities of the team, the strength and just kind of allocate.\\nSo it's a very tough off work.\\n\\n\\nIllig, Selma   33:34\\nYeah.\\nYeah.\\nAnd then maturity of your project, you know in the beginning when there's a lot of experimentation that improvements needed, you need lots more data science resources, but then at some point when it's only, you know, maintenance and maybe like a little bit of a B testing, but like no big concept changes anymore, you need way more engineers than you than you think.\\n\\n\\nBaghdadlian, Serop   33:37\\nYou know.\\nYeah, that's that's true.\\nThat's true.\\nBut like, how would you then efficiently allocate in the allocator?\\nYou cannot just hire people for like six months and then fire them, or you also, especially for like a rigid structure like a very big giant companies, it's very hard to move people around from what I heard, there's like budget restraints and usually your budget is allocated to a specific product.\\nSo you cannot do this fluctuation that comes with the challenges of maturity of the product.\\nWhich is something very interesting and a lot of people are not talking about this, although I assume that a lot of people or a lot of companies are facing the same issues.\\nBut it seems to nobody have figured out an efficient way to reallocate resources easily and always.\\n\\n\\nIllig, Selma   34:43\\nYeah.\\n\\n\\nBaghdadlian, Serop   34:44\\nYeah, especially in Germany, we love bureaucracy and stuff like this, so it's very we.\\n\\n\\nIllig, Selma   34:47\\nOK.\\nWe love our budgets.\\n\\n\\nBaghdadlian, Serop   34:51\\nYeah, we do.\\nWe do love our budgets, but yeah, it's it's tough.\\n\\n\\nIllig, Selma   34:54\\nI I think they're again, it's a, it's a very niche problem for these more established companies because they are the ones with these budget processes and where, you know everything is very strict and you have to go through this process and through this maybe group of people in order to get a new person or maybe just to move a position from one team to the other.\\nOne idea that I mean we are also thinking about right now are discussing about is you know putting data people higher up in the organization.\\nSo instead of assigning them to a product, assign them to a solution or even to the unit.\\nAnd maybe that would also already make it a little bit easier to, you know, shuffle things around and and prioritized and deprioritized search and projects.\\n\\n\\nBaghdadlian, Serop   35:32\\nUmm.\\nMm-hmm.\\n\\n\\nIllig, Selma   35:42\\nUmm but yeah, it it comes again with more complexity, because then you're part of the unit.\\nYou're very high up.\\nYou have a very you have a different kind of view on the organization and then you're not as deep into these product and their processes and their developments anymore.\\nSo that's one problem.\\nUmm yeah, but I think it could be worth exploring.\\nIs seeing, you know if we assign instead of having two.\\nDo you know data assigns product teams within the marketing domain of the customer unit?\\nMaybe you know, put us to the customer unit and say, well, you are responsible for all customer topics within Metro.\\n\\n\\nBaghdadlian, Serop   36:20\\nUmm.\\n\\n\\nIllig, Selma   36:21\\nSo let's see what kind of different options are there?\\nI would assume also exploring new ideas could be then easier cause you are connected to more you know product managers from different products and solutions and thus also better connected to the business decoders coming from Metro AG.\\n\\n\\nBaghdadlian, Serop   36:42\\nMm-hmm.\\n\\n\\nIllig, Selma   36:43\\nAnd then it's maybe not so much on the.\\nSkill and and networking capabilities of your product manager.\\nIf they hear about certain evolvement.\\nBut yeah, it's a very different structure than which I don't think we've seen anywhere else, maybe with the architecture, software architects.\\n\\n\\nBaghdadlian, Serop   37:01\\nUmm.\\n\\n\\nIllig, Selma   37:03\\nI think having a similar approach where they are a little bit higher up in the organization and Support more teams, but yeah, comes with a new set of of problems and challenges and things were probably don't think about yet.\\n\\n\\nBaghdadlian, Serop   37:09\\nHmm.\\nOK.\\nYeah.\\nUmm did you see?\\nLike, what's a data engineer would be doing in a startup like is it very different than what you guys are doing here in this like a big corporate?\\n\\n\\nIllig, Selma   37:31\\nYeah.\\nUmm, so it's very different I think so.\\nWe like as in you and me, are part of the data domain of Metro Digital, so we are supporting our little data product teams and the data scientists.\\nSo we are very far down the value stream already we are you know taking data that is available and we try to derive value from it for stakeholders.\\nData engineers in a classical sense, you know, move data from A to B.\\nSo if you go into a startup at some point you need to have these data engineers that are actually know responsible for collecting and ingesting and storing data.\\nSomething that the two of us don't really have to think about because we have the data like we're consuming data from the data.\\n\\n\\nBaghdadlian, Serop   38:15\\nUmm.\\n\\n\\nIllig, Selma   38:17\\nLake, you know there's there are different teams at Metro who focus a little bit more on that side, but they're again, it's very specialized and they do a very specialized set of things, whereas we probably also go more into this machine learning engineer type, which knows this new thing.\\n\\n\\nBaghdadlian, Serop   38:18\\nThat's true.\\n\\n\\nIllig, Selma   38:35\\nAnd then we also have analytics engineers.\\nNow were kind of preparing the data models already looking at this transformation layer and metric layer.\\nUmm, so the bigger your company gets, the more and also the more mature your company gets, the more data you collect, the more teams you have, the more specialized your roles get.\\nBut then, in a way, I also have the feeling that we are not specialized at all because in our little product teams, we also have to take care of security of infrastructure of different tasks that could be its own engineering role already.\\nUmm.\\nAnd I think this is where it really comes this, like every company is doing it a little bit differently and you will never be able to fulfill all job requirements.\\n\\n\\nBaghdadlian, Serop   39:18\\nUmm.\\n\\n\\nIllig, Selma   39:23\\nUmm, but yeah, highly specialized.\\nBut then, in a way also not specialized for us, where you know in startups.\\nUmm, I don't know.\\nYou probably also have to do a lot of different things like whatever is most important right now.\\nMaybe you know they start hiring their first data scientists and then out of a sudden you have to support them more.\\n\\n\\nBaghdadlian, Serop   39:44\\nUmm.\\n\\n\\nIllig, Selma   39:44\\nI think that's a little bit more, uh, table for us where, you know, it's pretty clear what the job is, what the team is, what we're doing the next year.\\n\\n\\nBaghdadlian, Serop   39:52\\nYeah.\\nThat's true.\\nYou mentioned that you're working on a churn use case, so I think we mentioned this previously in in our podcast.\\nJust maybe a reminder, so the churn means that the customer is gonna significantly stopped buying from whatever.\\n\\n\\nIllig, Selma   40:12\\nSecond, there were significant drop in sales.\\nExactly.\\n\\n\\nBaghdadlian, Serop   40:15\\nYeah.\\n\\n\\nIllig, Selma   40:15\\nYeah.\\n\\n\\nBaghdadlian, Serop   40:15\\nOK.\\n\\n\\nIllig, Selma   40:16\\nSo we try to.\\n\\n\\nBaghdadlian, Serop   40:16\\nAnd you're trying to predict when this is going to happen.\\nSo you're the sorcerer that will flag these customers before they even know it.\\nIt's like, oh, you're gonna stop coming to us in three months.\\n\\n\\nIllig, Selma   40:25\\nExactly erected.\\n\\n\\nBaghdadlian, Serop   40:28\\nWhich I found it super fascinating that we can do this.\\nUmm yeah.\\n\\n\\nIllig, Selma   40:31\\nYeah.\\nYeah, well, hopefully, but we we have quite we have quite good besides right now and it's basically this foundation for you know Metro digital build this huge CDP project together with the IBM X and Adobe where we have this marketing automation platform now.\\n\\n\\nBaghdadlian, Serop   40:34\\nHopefully they don't.\\n\\n\\nIllig, Selma   40:50\\nSo they harmonized basically all marketing campaigns from all countries.\\n\\n\\nBaghdadlian, Serop   40:58\\nMm-hmm.\\n\\n\\nIllig, Selma   40:58\\nAnd so we are the data foundation for one of the use cases, the churn prevention use case.\\nAnd yeah, we're predicting customers, we're about to buy less and hopefully with our marketing efforts.\\n\\n\\nBaghdadlian, Serop   41:04\\nMm-hmm.\\nBy less.\\nThey would not.\\n\\n\\nIllig, Selma   41:13\\nYeah, they they won't.\\n\\n\\nBaghdadlian, Serop   41:16\\nOK, maybe you can tell us how things so you work with two more people or three more people, right?\\n\\n\\nIllig, Selma   41:17\\nYeah.\\n\\n\\nBaghdadlian, Serop   41:23\\nSo you have a product manager, another engineer, and a data scientist.\\nSo tell us like, what do you kind of do for the data scientists to do their work efficiently?\\nDo you prepare the data?\\nDo you do the modeling or the the comment?\\nJust walk us through like a typical day.\\n\\n\\nIllig, Selma   41:43\\nYeah, typical day.\\nSo yeah, yeah.\\n\\n\\nBaghdadlian, Serop   41:49\\nMaybe two months.\\nI know like on a on a day to day, not a lot of things have happened.\\nGo through a trickle month.\\n\\n\\nIllig, Selma   41:55\\nNo, no, no Sir.\\nSo with our team we have this.\\nBeautiful thing that we can rely on the data model of a different team, so we have this kind of.\\n\\n\\nBaghdadlian, Serop   42:08\\nUmm.\\n\\n\\nIllig, Selma   42:10\\nStar Schema where a lot of the transactional data from Metro has already transformed and you know, cleaned and prepared by another team.\\nAnd so luckily, the data collection process is very easy for us because we just use their data which you know you have this dependency of.\\n\\n\\nBaghdadlian, Serop   42:24\\nUmm.\\nUmm.\\n\\n\\nIllig, Selma   42:30\\nYou know, we need to rely on them to actually be up to date and to provide the data relatively fast, but then we can use that for coming up with the concerts for our analysis that we've done while creating the project.\\nAnd this is where I also do work.\\nSo some of this, you know, exploratory analysis.\\nThat kind of topics then Felix, our data scientist, is the one creating the concept, training the model for the first time, analyzing results.\\nSeeing, you know, is that the way we want to go about and then we got a Jupiter notebook and this is no shame on that.\\n\\n\\nBaghdadlian, Serop   43:04\\nUmm.\\nNo shame in that.\\n\\n\\nIllig, Selma   43:11\\nAs I said, I love it and you know this is where we, you know, split it up, make sure into scripts the like make sure infrastructure and business logic and all of that is nicely separated where we create config files.\\nSo we can actually automate the whole thing.\\nSo best case, when we so initially the 1st.\\nYou see what with four countries, the Big Mitchell countries, so Spain, France, Germany and Romania, and then you know, it was just the one line config change to actually have it for like 11 additional countries.\\nAnd so we trained, you know, just with A1 liner change, she trained 11 war models and you do predictions for 11 more countries.\\n\\n\\nBaghdadlian, Serop   43:48\\nHello.\\n\\n\\nIllig, Selma   43:54\\nSo this is kind of the things that I'm working on, making sure that creating more countries, adding more features is actually a very minimal code changes.\\n\\n\\nBaghdadlian, Serop   43:54\\nUmm.\\nMm-hmm.\\n\\n\\nIllig, Selma   44:06\\nUmm.\\nAnd then now I'm monitoring our weekly run.\\nSo every Monday we do new predictions and then monthly in the the first week.\\n\\n\\nBaghdadlian, Serop   44:28\\nUmm.\\n\\n\\nIllig, Selma   44:28\\nEverything and now we are in case we went live.\\nNow I think we can say that now.\\n\\n\\nBaghdadlian, Serop   44:35\\nCongratulations. Nice.\\n\\n\\nIllig, Selma   44:36\\nThank you.\\nAnd now we're monitoring the results.\\nNo, seeing like also very looking from a very business perspective of what changed in the sales amount and what results can we see this customers continue buying even though we said they're going to be churners that they use the vouchers, they get that they interact with our emails for example, but then also on our side preparing for AB tests, I think this is also always something people think you know, it's just the small thing that maybe know it from software engineering.\\n\\n\\nBaghdadlian, Serop   44:40\\nUmm.\\nUmm.\\n\\n\\nIllig, Selma   45:09\\nIt's the button red or green?\\n\\n\\nBaghdadlian, Serop   45:10\\nUmm yeah.\\n\\n\\nIllig, Selma   45:10\\nAnd does it have more clicks?\\nBut you know in in machine learning it's a little bit more complex.\\n\\n\\nBaghdadlian, Serop   45:16\\nYes.\\n\\n\\nIllig, Selma   45:17\\nUmm but yeah, this is what's about to come down, which I'm most excited about because I have not done an AB test in production, you know, in a company with that amount of data.\\n\\n\\nBaghdadlian, Serop   45:26\\nUmm.\\n\\n\\nIllig, Selma   45:26\\nSo that's also curious what the other colleagues were saying.\\nYou know when we share our approach and they probably have some feedback.\\n\\n\\nBaghdadlian, Serop   45:36\\nUmm, yeah, of course I know that we all love tools.\\nSo you mentioned a lot of really cool stuff that you guys are doing.\\nOne particular is with a minimal code change.\\nYou now roll out in a lot of different countries.\\nUmm, maybe from my understanding, how does that scale up?\\nLike what are you using?\\nWhat infrastructure?\\nHow can you all of a sudden roll out to like 10 different more countries with an ease of or like a click of a button?\\n\\n\\nIllig, Selma   46:05\\nYeah.\\nSo for that example we have our config files where we, you know also specify you know the tables were using the columns that are used, the countries we are creating models for and then everything happens there and then it's all automated to be Argo right now which I think you know after we we saw vertex pipelines and how complex it is to to put it into a notebook and we we decided to stick with our goal.\\n\\n\\nBaghdadlian, Serop   46:22\\nUmm.\\nUmm.\\n\\n\\nIllig, Selma   46:31\\nWe know it's a lot more engineering overhead and if I would be a single data scientist working somewhere, I would not do it because you have to maintain that Community.\\n\\n\\nBaghdadlian, Serop   46:31\\nUmm.\\nUmm Yep.\\n\\n\\nIllig, Selma   46:38\\nJust cluster and you you have to write YAML files which I think is also you know very specific for for engineers they love it but nobody else loves it.\\n\\n\\nBaghdadlian, Serop   46:46\\nUmm.\\nYaml files are tough.\\nYeah, tough hate, hate, hate, love.\\nKind of relationship.\\n\\n\\nIllig, Selma   46:54\\nExactly.\\nExactly.\\nBut yeah, we are very happy with it cause it's scales where you have this parallelization so you know we do the predictions for all eleven countries basically at the same time.\\nUmm and yeah, it works well for us.\\n\\n\\nBaghdadlian, Serop   47:05\\nMm-hmm.\\n\\n\\nIllig, Selma   47:08\\nWe might have to know reconsider depending on what Google Cloud, not us with vertex AI and they keep adding new functionality and I'm I'm proving things and it seems to get this kind of standard thing that also a lot of our teams are using.\\n\\n\\nBaghdadlian, Serop   47:16\\nNo.\\n\\n\\nIllig, Selma   47:22\\nSo you know, it might make sense at some point to also switch to it.\\n\\n\\nBaghdadlian, Serop   47:23\\nYep.\\nYeah.\\nAnd this is at least what?\\nYeah, this at least what we were using at our team, the vertex AI.\\nIt also has a steep learning curve.\\nIt's not like as easy as it is, but yeah, maybe just for the big picture.\\nSo you're on Google Cloud platform, right?\\nAnd you have there some sort of Kubernetes cluster I assume.\\nUmm.\\nAnd with this, the what he said Argo workflow is that you're using.\\n\\n\\nIllig, Selma   47:49\\nToggle, yeah.\\n\\n\\nBaghdadlian, Serop   47:49\\nSo this orchestration tool that you can run parallel jobs is it does it allow you also to run on GPUs, right?\\n\\n\\nIllig, Selma   47:52\\nExactly.\\n\\n\\nBaghdadlian, Serop   47:57\\nSo the training is on GPUs or in your case you don't need GPUs for the training.\\n\\n\\nIllig, Selma   48:03\\nWe don't.\\nUh, it's an extra boost model that's under under all of our predictions.\\n\\n\\nBaghdadlian, Serop   48:04\\nYou don't, OK?\\n\\n\\nIllig, Selma   48:08\\nAnd then in the end, we do batch predictions.\\n\\n\\nBaghdadlian, Serop   48:09\\nUmm.\\n\\n\\nIllig, Selma   48:11\\nSo you know, it's also not so like times, not of the matter.\\n\\n\\nBaghdadlian, Serop   48:12\\nOK.\\nHmm, so bash prediction means you do these calculations every month?\\n\\n\\nIllig, Selma   48:18\\nThe.\\nEvery month.\\nEvery Monday we we run a our model again basically and it predicts the customers that for next week are have a high likelihood of churning.\\n\\n\\nBaghdadlian, Serop   48:24\\nAnd what happens?\\n\\n\\nIllig, Selma   48:35\\nUmm basically for for the next three months time period we look at.\\n\\n\\nBaghdadlian, Serop   48:35\\nMm-hmm.\\n\\n\\nIllig, Selma   48:40\\nYeah.\\nAnd that's what happens weekly.\\nAnd that's why, you know, if it's.\\nIf something happens real time you would you need these more intensive resources, but for us we do it Monday morning at 4:00 and if it takes an hour of it takes 1 1/2.\\nIt doesn't matter.\\nSo we try to to be, as you know less resource intensive.\\n\\n\\nBaghdadlian, Serop   48:54\\nMm-hmm.\\n\\n\\nIllig, Selma   48:59\\nSo we also don't pay so much.\\n\\n\\nBaghdadlian, Serop   48:59\\nUmm, but it's usually like, yeah, it's usually like an hour or like a a day or two.\\nIf you train the model.\\n\\n\\nIllig, Selma   49:04\\nNo, no, no, no.\\nLike the model, training itself takes about 20 minutes.\\nUmm.\\n\\n\\nBaghdadlian, Serop   49:11\\nOhh OK, that's good.\\n\\n\\nIllig, Selma   49:11\\nAnd then you know, with everything around it, all the different processes and for the marketing platform, we have to export some files as well.\\nAnd so that whole thing takes around 2 hours until all.\\n\\n\\nBaghdadlian, Serop   49:23\\nUmm and how is the scheduling?\\nSo how how do you schedule it on a Monday?\\nAre you using something with GitHub actions or is it something with Argo workflows or what?\\n\\n\\nIllig, Selma   49:32\\nThat's that's an inaugural.\\nThat's where you specify.\\n\\n\\nBaghdadlian, Serop   49:34\\nOhh OK.\\n\\n\\nIllig, Selma   49:36\\nWhen you want to run at half, you wanna run it and that's all customizable.\\n\\n\\nBaghdadlian, Serop   49:39\\nMm-hmm.\\nYeah, from complexity.\\nDo you think reaching the stage where you are now how much time would it take?\\nMaybe a one person to build such a thing like you need to.\\nWhat?\\nLet's let's let's build it into parts.\\nYou need to have like a cluster ready Kubernetes and like these workflows and assuming you have a script that runs like you don't have to do it.\\n\\n\\nIllig, Selma   49:59\\nYeah.\\n\\n\\nBaghdadlian, Serop   50:05\\nMaybe the data science would give it to you, but building those two parts, would it take like a month?\\n\\n\\nIllig, Selma   50:07\\nYeah.\\n\\n\\nBaghdadlian, Serop   50:10\\nThree months?\\nYou're a rough estimation.\\n\\n\\nIllig, Selma   50:13\\nIt's very hard for me to estimate.\\nLike I I I couldn't imagine like a month.\\nProbably if somebody has done it 1000 times already, then probably way faster.\\n\\n\\nBaghdadlian, Serop   50:19\\nUmm.\\nUmm.\\n\\n\\nIllig, Selma   50:22\\nI think what is part of that is this complexity within Metro Digital.\\nSo for example for, for logging and monitoring we also use data Dog for example.\\nSo if you have worked with that before, it's very easy to integrate.\\n\\n\\nBaghdadlian, Serop   50:32\\nOhh yeah OK.\\n\\n\\nIllig, Selma   50:37\\nBut when I started with my internship, understanding all of this took me around for a month.\\n\\n\\nBaghdadlian, Serop   50:37\\nMm-hmm.\\n\\n\\nIllig, Selma   50:42\\nSo from joining to actually being able to develop something on my own was probably four months and there's so much tools and yeah, I'll, I'll understanding how metal works and you know, just having our own organizations get up, get up organization, you know, knowing these kind of things takes you a while.\\n\\n\\nBaghdadlian, Serop   50:43\\nYeah.\\nYou know.\\nUmm.\\nAnd, well, interesting.\\n\\n\\nIllig, Selma   51:08\\nAnd so yeah, I mean, I was also, you know, Super Junior and first real job kind of.\\n\\n\\nBaghdadlian, Serop   51:12\\nYeah, yeah.\\n\\n\\nIllig, Selma   51:14\\nBut yeah, I would say it took me 4 months.\\n\\n\\nBaghdadlian, Serop   51:14\\nMm-hmm.\\nYeah, but that's that doesn't sound too unreasonable.\\nLike it took me also around four months just to understand the data like people also underestimate how much time it took me to understand the the, the just the data that you're working with.\\nAnd luckily, if you have like such a cool product like this star schema that you mentioned, so somebody actually sat down, maybe just to explain to people what that means, you have people who sat down, they saw all the data scattered somewhere and they put it into one place that is well documented.\\n\\n\\nIllig, Selma   51:28\\nYeah.\\n\\n\\nBaghdadlian, Serop   51:44\\nWell, every detail for every column is documented.\\nThe data is up to date. Everything is.\\nYou don't have to worry about anything.\\nJust use it, then it takes you way less time because you can just rely on this one point and you don't have to worry about everything else.\\nBut that was a product that started because people were struggling from finding these data sources and contacting these random people and like following people to just get like another table and have it in one place.\\nSo that took a long time, and if that exists then it accelerated the process.\\nIf it doesn't exist, it's very much more time.\\nThat's just to understand the data and every company has their own tech stack.\\nSo with a billion different tools, so we just mentioned like so many different tools and at my team, we also like the engineers using maybe six other different tools as well.\\nThat's you need to be familiar with and it's unrealistic to know all of these like and.\\nThis is all maybe specific to GCP at some point, but if I mean ideally Kubernetes, you can migrate to somewhere else, but also depending whether you're using like let's say, now we you go somewhere where they use AWC, then you need to also AWS.\\nSorry that you need to know also about their stuff.\\nYeah, it's not fun.\\nSo I highly doubt.\\nMaybe.\\nWell, I don't know the do you think janai is get a replace us any anytime soon.\\nIs that coming across your brain?\\n\\n\\nIllig, Selma   53:15\\nI don't think so.\\nJust because of that complexity, and I mean I guess we can say that I think all of us are using genei and some and type in their daily work that would be copilot or let it be asking Chachi PT to create SQL queries for me.\\n\\n\\nBaghdadlian, Serop   53:25\\nYep.\\nI do the same.\\n\\n\\nIllig, Selma   53:36\\nIt's just the best.\\nWhat do I know?\\nThese complex thing?\\nNo, it really helps and I think you know it makes you way faster, but there's still so much complexity and in the end talking to stakeholders is also very difficult.\\nAnd but having this human relationship also very much helps there.\\n\\n\\nBaghdadlian, Serop   53:57\\nHmm.\\n\\n\\nIllig, Selma   53:57\\nIt's not all about, you know, the technical details.\\nLot about trust and data products, you know, and it there you can't replace the human so fast, but let's see.\\n\\n\\nBaghdadlian, Serop   54:01\\nYeah.\\nHmm.\\n\\n\\nIllig, Selma   54:09\\nI'm not up for writing down the files my whole life, so maybe they can take over that.\\n\\n\\nBaghdadlian, Serop   54:13\\nMaybe they can take over that part.\\nOK.\\nYeah, fair enough.\\nEnough.\\nBut it's also interesting that now there's also a lot of products that they take over all this heavy lifting for you, like you could do your own cluster or you could do a managed thing.\\nUh, I actually don't know the pros and cons.\\nI know that we do our own thing because it adds flexibility into doing what you need and this fully managed service.\\nThere are costly like a lot costlier and they are not super flexible.\\nBut also engineers are costly, so I don't know.\\nThat's something that we need to explore, or maybe companies need to explore as well.\\nAnd maybe you need less people to manage these things.\\nBut yeah, learning so many new tools is is tough because they also last month they have a lifespan of like I don't know, two or three years and then all of a sudden like, oh, you're using that.\\nYeah, you know, like it's like outdated.\\nAnd then like like, I only just learned it.\\nOhh, so yeah, it's it's difficult.\\nNo question for you how was working as a data engineer.\\n\\n\\nIllig, Selma   55:14\\nSure, sure.\\n\\n\\nBaghdadlian, Serop   55:19\\nDo you like it so far?\\nWould you like to improve stuff?\\n\\n\\nIllig, Selma   55:23\\nYeah.\\nNo, I am a very big fan of, especially because it's so versatile.\\nLike there are no weak is the same then your request and new things we can do which are very much like I think getting into it is very hard.\\nSo I had this, you know, beautiful opportunity of doing the internship and then joining full time in the same team, kind of on the same project again, which made it, of course way easier to to break into the field.\\n\\n\\nBaghdadlian, Serop   55:48\\nUmm.\\n\\n\\nIllig, Selma   55:52\\nBut then you know, if you look at all of the things people need to do from later lifecycle management to software engineering skills, infrastructure skills, security skills like, there's so much where it's very hard for juniors to break into the space and.\\nYeah, I've also understand what you learn first, because there's so many opinions out there from you need to go back to the complete basics and do math 1st to well learn these as you just said before these like 5 new hot tools and then you immediately get a job.\\nBut then you know what happens afterwards if that tool is out of date again and you have to find a new job.\\nUmm, which I think is so tough and that's where you realize so much and like a good mentor, a good person to like, sit down with you and create a development plan and figure out what are the actual important skills, which is usually not learning the new software or learning math, but somewhere in between.\\n\\n\\nBaghdadlian, Serop   56:45\\nUmm.\\n\\n\\nIllig, Selma   56:51\\nYeah.\\n\\n\\nBaghdadlian, Serop   56:53\\nSo if you go back to your ohh sorry.\\n\\n\\nIllig, Selma   56:53\\nThere's.\\nWell.\\n\\n\\nBaghdadlian, Serop   56:58\\nNo, no, you go.\\nWhat?\\nWhat do you wanna say?\\n\\n\\nIllig, Selma   57:00\\nI but nothing and I was just filling the void.\\n\\n\\nBaghdadlian, Serop   57:02\\nOhh nothing, OK uh, my question, no worries.\\nNo, there's no word.\\nAll good.\\nMy question was if so, if you would go back to your student, you said like it was very difficult to kind of know the right path if you would go back to the beginning, how would you structure it differently or what would you have done differently?\\n\\n\\nIllig, Selma   57:23\\nUmm I am quite happy how I did it because I I think at university like do the things you like and you think are fun and the things you're interested in this like then you will always learn way more than you know.\\nIf you look at your syllabus and be like, oh, I think in order to get this in that job, I need to take these courses.\\nBut then you hate them and you, you cannot passionate about them and you don't learn a lot.\\n\\n\\nBaghdadlian, Serop   57:44\\nHmm.\\n\\n\\nIllig, Selma   57:49\\nThen, if you actually take the things you're interested in, you go way further and beyond just the things that are listed on your course outline.\\nSo this would be the first thing like we need to do the things you are interested in, and then the other thing is to internships.\\nI think it it sucks because a lot of people are also not offering any in the data field, but I think it's the easiest way to break into the industry because then you realize what you do at university is nice and it's a good foundation.\\nSo you've heard about these things, but then actually applying it in a company with your stakeholders and your company's data, very different animal.\\nYou know that that step from working on you know these predefined data sets that are pre cleaned and prepared for.\\n\\n\\nBaghdadlian, Serop   58:27\\nHmm.\\n\\n\\nIllig, Selma   58:37\\nYou know academic purposes and very different than what you then actually get here, and there's a lot of skills around it that you learn when you start working, which are more valuable to have for than companies hiring you.\\n\\n\\nBaghdadlian, Serop   58:42\\nUmm.\\n\\n\\nIllig, Selma   58:54\\nThen if you know if you did your second advanced machine learning course at university, because you will most likely never use any of these very complex neural networks at work because they're too expensive and too time intensive to train.\\n\\n\\nBaghdadlian, Serop   58:54\\nUmm.\\nUmm. Mm-hmm.\\n\\n\\nIllig, Selma   59:11\\nSo yeah, I would recommend people to to start working early.\\nIt makes a difference.\\n\\n\\nBaghdadlian, Serop   59:16\\nThat's a very good point.\\nI also agree with you, it's just totally different.\\nWhat's your opinion on like online courses?\\nHave you ever had an online course where you like what like this is so applicable that I want to use it tomorrow? Umm.\\n\\n\\nIllig, Selma   59:31\\nUh, I think in the beginning there are few, so I am a big fan of, you know, this addicts, especially at the Harvard ones on computer science.\\n\\n\\nBaghdadlian, Serop   59:40\\nHmm.\\n\\n\\nIllig, Selma   59:42\\nAnd you know there there are these amazing instructor out there that you can use basically for free and learn.\\nI'm also a big fan of Datacamp in a way that the way they structure their courses just make a lot of sense and they they push you, but they're not too complex, and they also have these nice exercises.\\n\\n\\nBaghdadlian, Serop   59:53\\nUmm.\\nUmm.\\n\\n\\nIllig, Selma   1:00:03\\nActually, you know, apply it.\\nIt goes further than just using the Titanic data set.\\nYou know which I think is the standard machine learning data stand that everyone did, but you have to go further.\\n\\n\\nBaghdadlian, Serop   1:00:13\\nYes.\\n\\n\\nIllig, Selma   1:00:14\\nIt's not enough to just work on that like.\\n\\n\\nBaghdadlian, Serop   1:00:16\\nNo, that's true. Mm-hmm.\\n\\n\\nIllig, Selma   1:00:17\\nAlso, nobody wants to see that on your CV anymore because you know everyone did it already.\\n\\n\\nBaghdadlian, Serop   1:00:21\\nNo, no, please don't.\\nDon't put it to your CV.\\nThat's nobody cares.\\n\\n\\nIllig, Selma   1:00:26\\nExactly.\\n\\n\\nBaghdadlian, Serop   1:00:27\\nOK, so you're saying use the use the online courses in the like the introduction part and then as soon as you can just get a job just intern unpaid.\\n\\n\\nIllig, Selma   1:00:27\\nExactly. Yeah.\\nYeah.\\n\\n\\nBaghdadlian, Serop   1:00:38\\nWhatever it is, just get some experience, because now also everybody's asking for experience and I find it funny that, I mean, Jenna, I, the way we see it now has been.\\n\\n\\nIllig, Selma   1:00:43\\nYou know.\\n\\n\\nBaghdadlian, Serop   1:00:48\\nI don't know, like one year that's like or two years, maybe that people know about it and you see jobs like five years of Chennai experience.\\n\\n\\nIllig, Selma   1:00:51\\nHmm.\\n\\n\\nBaghdadlian, Serop   1:00:55\\nLike, what do you mean?\\nFive years.\\nWhere am I gonna get that?\\nYou know, like so, but yeah, don't worry about this.\\nLike people have unrealistic expectations and but yeah, I I also agree.\\nUh, But here's here's where the challenge lies.\\nBecause we all want to learn something new and upskill ourselves and maybe have a little bit more advanced knowledge.\\nBut then the courses that they say we are like advanced in a certain thing.\\nI honestly have never really learned much from them and I try to like now the only thing what I learn a lot is when I enter a field what I done nothing and then I do a course and then it's actually helps me.\\nIt's like, OK, I didn't know about that.\\nI can use it now like know the basics and then it's all business practical knowledge that you need to apply yourself.\\nThere's no course that will show you what you need over there.\\n\\n\\nIllig, Selma   1:01:44\\nYep.\\nWhat I tend to do, and I think this is also the only way that works if you know nothing about the field, you don't even know what to Google.\\nBasically, and then if you do an introductory course, you kind of you learn the terminology and everything.\\nThen you can.\\nMaybe you already have a business problem that would use that technique or whatever, and then you, you know, you can structure your learning better because you kind of know what's expected and what you should be doing.\\nAnd you can apply it right away, and that's overlearning really sticks.\\nUmm, but if you just do a course for doing a course it it won't stick and you you don't go deep enough again.\\nIt's very superficial.\\nJust listening to somebody explaining something.\\n\\n\\nBaghdadlian, Serop   1:02:28\\nUmm, OK, interesting.\\n\\n\\nIllig, Selma   1:02:28\\nYeah.\\n\\n\\nBaghdadlian, Serop   1:02:31\\nUh, out of curiosity, how many women were in your educational program?\\nBecause you're like a female engineer.\\nWe're very happy to have you.\\nI know there's like this little bit gap in female engineers nowadays.\\nHow was your experience being an engineer?\\nHow would you maybe empower empower more women to join the field?\\nAnd I know it is maybe scary because they scary with math or whatever or I don't know, because it's also sometimes highly male dominated the industries.\\nHow was your experience?\\nHow would you maybe empower more women to join the engineering heavy engineering sectors?\\n\\n\\nIllig, Selma   1:03:12\\nSo admire university.\\nWe were around 20% women in the software engineering course, which I think is it's OK, you know, you knew your fellow women in the course.\\n\\n\\nBaghdadlian, Serop   1:03:19\\nUmm.\\n\\n\\nIllig, Selma   1:03:23\\nAnd then we tried to support each other.\\nI think what is very scary, if you look at the field is this.\\n\\n\\nBaghdadlian, Serop   1:03:26\\nNice.\\n\\n\\nIllig, Selma   1:03:29\\nYou have a lot of people where, you know, programming is their passion and they have been doing it since.\\nThey're six and got the first computer from their uncle and then they haven't stopped doing it.\\nBasically, they only interrupted to.\\n\\n\\nBaghdadlian, Serop   1:03:43\\nUmm.\\n\\n\\nIllig, Selma   1:03:45\\nMaybe you know, eat something and then they're back at it doing it, you know, in their free time, but also for work.\\nAnd their freelance.\\nAnd it's the only thing they do.\\nBut then if you start looking at it be like ohh engineering is actually or programming, it's just a tool that you can learn that it's also more similar to learning a foreign language than doing math.\\nEspecially, and I think this is kind of the critique I have about the the German university system is they only offer computer science usually, but computer science and software engineering are two very different things.\\n\\n\\nBaghdadlian, Serop   1:04:06\\nUmm.\\n\\n\\nIllig, Selma   1:04:20\\nAnd you know, if you look across the Atlantic, for example, I at least not from Canada, they offer both and both are very, you know, well known reputable study programs you can you can study in Germany, we only know informatic and depending on your university it can be very theoretical or it can be more practical.\\n\\n\\nBaghdadlian, Serop   1:04:36\\nYou know.\\n\\n\\nIllig, Selma   1:04:41\\nBut in the end it's all called informatic.\\n\\n\\nBaghdadlian, Serop   1:04:44\\nUmm.\\n\\n\\nIllig, Selma   1:04:44\\nBut then I started now software engineering and that has very little to do with informatic.\\nIt's really more about, you know, actually developing software.\\nIt's about collaborating this product managers with diners, it's.\\nIt's a lot about infrastructure and testing and things you can just you can learn.\\nThere's nothing magic about it.\\nThere's nothing really you need to understand in a way.\\nAnd if you start looking like this on programming and on software engineering, it gets less scary.\\nIt's it's not as scary anymore.\\nYou don't need to be good in maths or physics or whatever to actually study that.\\nIt's really more like learning a foreign language which you know is often more associated with women being good at it.\\nWhere I see you know, if you start looking at program like this, maybe there's something for you.\\nMaybe it's not so scary anymore.\\n\\n\\nBaghdadlian, Serop   1:05:39\\nUmm.\\n\\n\\nIllig, Selma   1:05:39\\nUmm but yeah, the field is still dominated like it.\\nI think we also, you know have this big problem of how to make a workspace inclusive for women, for mothers like it's it's this big.\\n\\n\\nBaghdadlian, Serop   1:05:49\\nHmm.\\n\\n\\nIllig, Selma   1:05:55\\nSupplied to you?\\nWell, like social problem?\\nThen just how do we get more women into programming, which I guess we have to start early and we have to switch how we talk about it and it's all happens in school.\\n\\n\\nBaghdadlian, Serop   1:05:58\\nYou know.\\nUmm yeah.\\n\\n\\nIllig, Selma   1:06:07\\nBut yeah, they're good initiatives out there now.\\nWho are really taking this on and trying to, yeah, get more girls and more women interested in this technical field.\\n\\n\\nBaghdadlian, Serop   1:06:21\\nUmm Yep, I totally agree with you by the way, with the with the comments about like they kind of scare you with this kind of stuff.\\nSo the math example was actually the thing that stopped me from entering software development, because I thought, like, Oh my God, like you have to be a math genius and there's like, you look at the fellow people who decide to go into informatic and they, as you said, like they have their laptops since they were six and they programmed, like, I don't know, apps.\\n\\n\\nIllig, Selma   1:06:45\\nNo.\\n\\n\\nBaghdadlian, Serop   1:06:49\\nAnd they show you it's like, oh, I can't compete with that.\\nLike I'm so in inferior to that.\\nUh, and then you enter the field like also like data science, it's the most.\\nIt's the job of the most different backgrounds that I saw.\\nLike you can end up being a data scientist doing so many different things.\\nI know people who were in recruitment and then ended up doing data science.\\nI know people who were doing neuro science and then decide to do data science and then became software developers or engineers and it's just very fluid the transitions.\\nAnd if you can learn, then you can also do it and it just learning a new tool or in a learning a new language.\\nI never saw this as ohh, just as learning a new language until I did it and then it was like ohh this is not math like I don't need to know cryptography.\\nI don't need to hack people like I can just.\\n\\n\\nIllig, Selma   1:07:40\\nNo.\\n\\n\\nBaghdadlian, Serop   1:07:42\\nIt's actually more soft skills than talking to people than people think.\\nYou need to kind of understand what they want or maybe push back and say like oh, this doesn't make sense.\\nRather than being this hacker with your hoodie and developing software until like 2:00 AM in the morning.\\n\\n\\nIllig, Selma   1:07:59\\nYeah.\\n\\n\\nBaghdadlian, Serop   1:08:00\\nSo it's.\\n\\n\\nIllig, Selma   1:08:00\\nAnd these people are also important in the company.\\nBut you know, if you look at your group of engineers, you have like, how many do you need that can actually optimize some kind of complex algorithm?\\nLike very few of them are the the big majority of them is now collaborating in teams, developing new pieces of software.\\nBut then again you add like a small feature to it.\\nThere's maybe already a preset structure you don't need to, you know, have deep knowledge and software design.\\nEach day you open your computer and then in the end if you need it, you again collaborate with a group of people that you don't need to be the the expert on everything all the time.\\n\\n\\nBaghdadlian, Serop   1:08:32\\nMm-hmm.\\nYeah.\\n\\n\\nIllig, Selma   1:08:40\\nAnd yeah, if you start looking at that, it just gets less scary and you see like, oh, I can actually achieve this.\\n\\n\\nBaghdadlian, Serop   1:08:41\\nYou know.\\nI agree.\\nAnd they still like if if you want to learn, I don't know software designs or it comes with the time, you know, like you can also build it up and then become like an architect or whatever.\\nSo it's also possible paths that you can take, but it's not the only path.\\nYou can also stay with those.\\n\\n\\nIllig, Selma   1:09:02\\nExactly.\\n\\n\\nBaghdadlian, Serop   1:09:04\\nYeah, the soft skill talking kind of type and, uh, Selma, this has been really, really nice.\\n\\n\\nIllig, Selma   1:09:06\\nYeah, yeah.\\n\\n\\nBaghdadlian, Serop   1:09:11\\nThank you so much for your insights.\\nI'd really appreciate having you here and I had a great time.\\nI hope our listeners would also pick up a thing or two from what we said, maybe design better the processes and their team structures optimize this kind of stuff.\\n\\n\\nIllig, Selma   1:09:17\\nYeah.\\n\\n\\nBaghdadlian, Serop   1:09:27\\nAnd yeah, thank you for being here.\\nI wish you a great success in your career.\\n\\n\\nIllig, Selma   1:09:29\\nYeah.\\nThank you for having me.\\n\\n\\nBaghdadlian, Serop   1:09:31\\nNow, it's my pleasure.\\n\\n\\nIllig, Selma   1:09:32\\nThank you.\\nThank you.\\nThat's fun.\\n\\n\\nBaghdadlian, Serop   1:09:33\\nPerfect.\\nHave a nice day.\\n\\n\\nIllig, Selma   1:09:35\\nThat's.\\n\\n\\nBaghdadlian, Serop   1:09:35\\nThank you.\\n\\n\\nIllig, Selma   1:09:35\\nYeah.\\n\\n\\nBaghdadlian, Serop   1:09:36\\nBye bye.\\n\\n\\nIllig, Selma   1:09:37\\nBye, bye.\\n\\n\\nBaghdadlian, Serop   1:09:39\\nRight.\\n\\n\\nBaghdadlian, Serop stopped transcription\")]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit just to the first 3 chunks\n",
    "# so the code can be re-run quickly\n",
    "first_few = all_splits[:1]\n",
    "\n",
    "extractions = extractor.batch(\n",
    "    [{\"text\": text} for text in first_few],\n",
    "    {\"max_concurrency\": 5},  # limit the concurrency by passing max concurrency!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've extracted the important keynotes from this podcast conversation:\\n\\n**Keynote 1:** The field of data science is becoming increasingly fluid, and it's not just for people with traditional backgrounds. Anyone can learn and transition into a career in data science.\\n\\n**Keynote 2:** Soft skills are crucial in data science. You need to be able to understand what others want or push back if something doesn't make sense. It's not just about hacking code or developing software.\\n\\n**Keynote 3:** Not all engineers need to be experts in complex algorithms. Many can focus on collaborating with teams, developing new software features, and optimizing existing ones.\\n\\n**Keynote 4:** You don't need to be an expert in everything to achieve your goals. Collaboration is key, and it's okay to focus on specific areas or build up skills over time.\\n\\nThese keynotes highlight the importance of soft skills, collaboration, and adaptability in a career in data science.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'key_developments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m key_developments \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m extraction \u001b[39min\u001b[39;00m extractions:\n\u001b[0;32m----> 4\u001b[0m     key_developments\u001b[39m.\u001b[39mextend(extraction\u001b[39m.\u001b[39;49mkey_developments)\n\u001b[1;32m      6\u001b[0m key_developments[:\u001b[39m10\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'key_developments'"
     ]
    }
   ],
   "source": [
    "key_developments = []\n",
    "\n",
    "for extraction in extractions:\n",
    "    key_developments.extend(extraction.key_developments)\n",
    "\n",
    "key_developments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
